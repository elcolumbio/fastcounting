{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created `%t` as an alias for `%timeit`.\n",
      "Created `%%t` as an alias for `%%timeit`.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from waipawama import Finance\n",
    "import pathlib\n",
    "import math\n",
    "import calendar\n",
    "import datetime as dt\n",
    "import redis\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "from mlrepricer import helper\n",
    "%alias_magic t timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you have to run everything exactly once to not run in bugs :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Belegdat.         int64\n",
       "Abschluss        object\n",
       "BetragEUR       float64\n",
       "Buchdat.        float64\n",
       "HabenEUR        float64\n",
       "Notiz            object\n",
       "Relation         object\n",
       "SollEUR         float64\n",
       "Status           object\n",
       "USt H-EUR       float64\n",
       "USt Haben       float64\n",
       "USt-S EUR       float64\n",
       "USt-EUR         float64\n",
       "USt Kto         float64\n",
       "USt Kto-H       float64\n",
       "USt Kto-S       float64\n",
       "USt %           float64\n",
       "USt Text         object\n",
       "Nr.             float64\n",
       "Jour. Dat.      float64\n",
       "Beleg            object\n",
       "Belegnr.         object\n",
       "Buchungstext     object\n",
       "Betrag          float64\n",
       "Whrg             object\n",
       "Sollkto         float64\n",
       "Habenkto        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = '2017-13'\n",
    "r = redis.Redis(**helper.rediscred, decode_responses=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main thing\n",
    "big_dict = dict()\n",
    "\n",
    "dfinput = read_lexware_journal(month)\n",
    "df = dfinput.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfinput.copy()\n",
    "df['Belegdat.'] = df['Belegdat.'].ffill() # that is a bit ugly but it should work every time and is a shortcut?\n",
    "# cant store pandas datatype timestamp in redis. Instead store 0 padded timestamp in seconds.\n",
    "df['Belegdat.'] = (df['Belegdat.'] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')\n",
    "df['Buchdat.'] = (df['Buchdat.'] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')\n",
    "df['Jour. Dat.'] = (df['Jour. Dat.'] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')\n",
    "\n",
    "df['Belegdat.'] = df['Belegdat.'].apply(str)\n",
    "\n",
    "first_walk(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Nr.'].ffill(inplace=True)\n",
    "dimensions = ['Sollkto', 'Habenkto', 'USt Kto-H', 'USt Kto-S']\n",
    "df.fillna(value={dimension: 0.0 for dimension in dimensions}, inplace=True)\n",
    "\n",
    "second_walk(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lexware_journal(month, nrows=None):\n",
    "    \"\"\"Read xlxs from the default folder for each year e.g. month=2018-13 or actual month.\"\"\"\n",
    "    p = pathlib.Path(f'{Finance().data}{month}')\n",
    "    files = [file for file in p.iterdir() if file.parts[-1].lower().startswith('journal')]\n",
    "    if files:\n",
    "        data = pd.read_excel(\n",
    "            files[0], bom=True, sep=';', encoding='latin-1', decimal=',', thousands='.',\n",
    "            dayfirst=True, skiprows=1, parse_dates=['Belegdat.', 'Buchdat.', 'Jour. Dat.'], nrows=nrows)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_walk(df):\n",
    "    \"\"\"\n",
    "    First of two walks for splitted multirow transactions only the first row\n",
    "    has general information, we run only over those here.\n",
    "    \"\"\"\n",
    "    for i in df.index:\n",
    "        # get unique id from database (threadsave)\n",
    "        generalID = r.incr('next_generalID')\n",
    "        # create temporary mapping\n",
    "        r.set(df.at[i, 'Nr.'], generalID, ex=300)\n",
    "        # store data in hash\n",
    "        r.hmset(f'generalID:{generalID}',\n",
    "            {'date': df.at[i, 'Belegdat.'],\n",
    "            'jourdat': df.at[i, 'Jour. Dat.'],\n",
    "            'buchdat': df.at[i, 'Buchdat.'],\n",
    "            'status': df.at[i, 'Status'],\n",
    "            'belegnr': df.at[i, 'Belegnr.']})\n",
    "        \n",
    "def append_big_dict(i, konto, betrag, ust=None):\n",
    "    # get temporary mapping we created in the first walk\n",
    "    generalID = r.get(df.at[i, 'Nr.'])\n",
    "    # get unique id from database (threadsave)\n",
    "    atomicID = r.incr('next_atomicID')\n",
    "    # create stable mapping- general:atomic:\n",
    "    r.sadd(f'general:atomic:{generalID}', atomicID)\n",
    "    # create mapping accountID:atomicID\n",
    "    r.sadd(f'account:atomic:{konto}', atomicID)\n",
    "    # create datefilter atomic:date\n",
    "    r.zadd('atomic:date', {atomicID: int(df.at[i, 'Belegdat.'])}) # could think about splitting the key into years\n",
    "    # store data in hash + mapping atomic:general + mapping atomic+account\n",
    "    r.hmset(f'atomicID:{atomicID}',\n",
    "           {'generalID': generalID,\n",
    "            'accountID': konto,\n",
    "            'text': df.at[i, 'Buchungstext'],\n",
    "            'amount': betrag})\n",
    "        \n",
    "def second_walk(df):\n",
    "    \"\"\"\n",
    "    Second and last walk, now we walk over every row and we unpack up to 4 dimensions per row.\n",
    "    There are 3 types of accounting transactions in this row based lexware export.\n",
    "    1. automatic transaction, like ust payment on revenues\n",
    "    2. split multirow transaction, like payment of import taxes and handling with dhl.\n",
    "        important to note you can make split multirow transactions with duplicated \n",
    "        accounts thats why we cant use a dictionary here.\n",
    "    3. standard account to account mapping\n",
    "    + every combination from the above\n",
    "    It comes handy that split multirow transaction are seperated in rows.\n",
    "    \"\"\"\n",
    "    for i in df.index:\n",
    "        if df.at[i, 'Sollkto']:\n",
    "            #r.zadd(df.at[i, 'Sollkto'], {})\n",
    "            append_big_dict(i, df.at[i, 'Sollkto'], -df.at[i, 'SollEUR'])\n",
    "\n",
    "        if df.at[i, 'Habenkto']:\n",
    "            append_big_dict(i, df.at[i, 'Habenkto'], df.at[i, 'HabenEUR'])\n",
    "\n",
    "        if df.at[i, 'USt Kto-H']:\n",
    "            append_big_dict(i, df.at[i, 'USt Kto-H'], df.at[i, 'USt H-EUR'])\n",
    "\n",
    "        if df.at[i, 'USt Kto-S']:\n",
    "            append_big_dict(i, df.at[i, 'USt Kto-S'], -df.at[i, 'USt-S EUR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
